Till now, we only try  Abstract Scenes Data.
Files download locations:

[Training annotations](https://s3.amazonaws.com/cvmlp/vqa/abstract_v002/vqa/Annotations_Train_abstract_v002.zip) 2015 v1.0 : 600,000 answers


[Validation annotations](https://s3.amazonaws.com/cvmlp/vqa/abstract_v002/vqa/Annotations_Val_abstract_v002.zip) 2015 v1.0 : 300,000 answers


[Training questions](https://s3.amazonaws.com/cvmlp/vqa/abstract_v002/vqa/Questions_Train_abstract_v002.zip) 2015 v1.0 : 60,000 questions


[Validation questions](https://s3.amazonaws.com/cvmlp/vqa/abstract_v002/vqa/Questions_Val_abstract_v002.zip) 2015 v1.0 :  30,000 questions


[Testing questions](https://s3.amazonaws.com/cvmlp/vqa/abstract_v002/vqa/Questions_Test_abstract_v002.zip) 2015 v1.0 :  60,000 questions


[Training images](https://s3.amazonaws.com/cvmlp/vqa/abstract_v002/scene_img/scene_img_abstract_v002_train2015.zip) :  20,000 images


[Validation images](https://s3.amazonaws.com/cvmlp/vqa/abstract_v002/scene_img/scene_img_abstract_v002_val2015.zip) :  10,000 images


[Testing images](https://s3.amazonaws.com/cvmlp/vqa/abstract_v002/scene_img/scene_img_abstract_v002_test2015.zip) :  20,000 images
